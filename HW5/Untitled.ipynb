{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            img_path  label\n",
      "0  ./256_ObjectCategories/139.megaphone/139_0010.jpg    139\n",
      "1  ./256_ObjectCategories/139.megaphone/139_0024.jpg    139\n",
      "2  ./256_ObjectCategories/139.megaphone/139_0075.jpg    139\n",
      "3  ./256_ObjectCategories/139.megaphone/139_0036.jpg    139\n",
      "4  ./256_ObjectCategories/139.megaphone/139_0013.jpg    139\n",
      "load dataset: \n",
      "x_train:  (963, 256, 256, 3)\n",
      "x_test:  (108, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "from utils import load_Caltech256_data\n",
    "from utils import extract_DenseSift_descriptors\n",
    "from utils import build_codebook\n",
    "from utils import input_vector_encoder\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "def build_spatial_pyramid(image, descriptor, level):\n",
    "    \"\"\"\n",
    "    Rebuild the descriptors according to the level of pyramid\n",
    "    \"\"\"\n",
    "    assert 0 <= level <= 2, \"Level Error\"\n",
    "    step_size = DSIFT_STEP_SIZE\n",
    "    from utils import DSIFT_STEP_SIZE as s\n",
    "    assert s == step_size, \"step_size must equal to DSIFT_STEP_SIZE\\\n",
    "                            in utils.extract_DenseSift_descriptors()\"\n",
    "    h = image.shape[0] / step_size\n",
    "    w = image.shape[1] / step_size\n",
    "    idx_crop = np.array(range(len(descriptor))).reshape(h,w)\n",
    "    size = idx_crop.itemsize\n",
    "    height, width = idx_crop.shape\n",
    "    bh, bw = 2**(3-level), 2**(3-level)\n",
    "    shape = (height/bh, width/bw, bh, bw)\n",
    "    strides = size * np.array([width*bh, bw, width, 1])\n",
    "    crops = np.lib.stride_tricks.as_strided(\n",
    "            idx_crop, shape=shape, strides=strides)\n",
    "    des_idxs = [col_block.flatten().tolist() for row_block in crops\n",
    "                for col_block in row_block]\n",
    "    pyramid = []\n",
    "    for idxs in des_idxs:\n",
    "        pyramid.append(np.asarray([descriptor[idx] for idx in idxs]))\n",
    "    return pyramid\n",
    "\n",
    "def spatial_pyramid_matching(image, descriptor, codebook, level):\n",
    "    pyramid = []\n",
    "    if level == 0:\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
    "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
    "        return np.asarray(code).flatten()\n",
    "    if level == 1:\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
    "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
    "        code_level_0 = 0.5 * np.asarray(code[0]).flatten()\n",
    "        code_level_1 = 0.5 * np.asarray(code[1:]).flatten()\n",
    "        return np.concatenate((code_level_0, code_level_1))\n",
    "    if level == 2:\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=0)\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=1)\n",
    "        pyramid += build_spatial_pyramid(image, descriptor, level=2)\n",
    "        code = [input_vector_encoder(crop, codebook) for crop in pyramid]\n",
    "        code_level_0 = 0.25 * np.asarray(code[0]).flatten()\n",
    "        code_level_1 = 0.25 * np.asarray(code[1:5]).flatten()\n",
    "        code_level_2 = 0.5 * np.asarray(code[5:]).flatten()\n",
    "        return np.concatenate((code_level_0, code_level_1, code_level_2))\n",
    "\n",
    "VOC_SIZE =100\n",
    "PYRAMID_LEVEL = 2\n",
    "\n",
    "DSIFT_STEP_SIZE = 4\n",
    "# DSIFT_STEP_SIZE is related to the function\n",
    "# extract_DenseSift_descriptors in utils.py\n",
    "\n",
    "\n",
    "    \n",
    "PATH = './img_list_mini.csv'\n",
    "# It contains 20 classes. each class has 50 images\n",
    "X, y = load_Caltech256_data(PATH)\n",
    "\n",
    "X = np.asarray(X)\n",
    "y = np.asarray(y)\n",
    "\n",
    "N = X.shape[0]\n",
    "idx = np.array(range(N))\n",
    "np.random.shuffle(idx)\n",
    "\n",
    "X = X[idx]\n",
    "y = y[idx]\n",
    "\n",
    "N_train = int(len(X)*0.9)\n",
    "x_train, y_train = X[:N_train], y[:N_train]\n",
    "x_test, y_test = X[N_train:], y[N_train:]\n",
    "\n",
    "print 'load dataset: '\n",
    "print 'x_train: ', x_train.shape\n",
    "print 'x_test: ', x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dense SIFT feature extraction\n",
      "Train/Test split: 963/108\n",
      "Codebook Size: 100\n",
      "Pyramid level: 2\n",
      "Building the codebook, it will take some time\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "print \"Dense SIFT feature extraction\"\n",
    "# memory...\n",
    "x_train_feature = [extract_DenseSift_descriptors(img) for img in x_train]\n",
    "x_train_kp, x_train_des = zip(*x_train_feature)\n",
    "del x_train_feature\n",
    "del x_train_kp\n",
    "gc.collect()\n",
    "\n",
    "x_test_feature = [extract_DenseSift_descriptors(img) for img in x_test]\n",
    "x_test_kp, x_test_des = zip(*x_test_feature)\n",
    "x_test_feature, x_test_kp = None, None\n",
    "del x_test_feature\n",
    "del x_test_kp\n",
    "gc.collect()\n",
    "\n",
    "print \"Train/Test split: {:d}/{:d}\".format(len(y_train), len(y_test))\n",
    "print \"Codebook Size: {:d}\".format(VOC_SIZE)\n",
    "print \"Pyramid level: {:d}\".format(PYRAMID_LEVEL)\n",
    "print \"Building the codebook, it will take some time\"\n",
    "codebook = build_codebook(x_train_des, VOC_SIZE)\n",
    "import cPickle\n",
    "# number of samples\n",
    "N = 1000\n",
    "with open('./spm_lv1_codebook.pkl','w') as f:\n",
    "    cPickle.dump(codebook, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial Pyramid Matching encoding\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "with open('./spm_lv1_codebook.pkl','rb') as f:\n",
    "    x = cPickle.load(f)\n",
    "\n",
    "print \"Spatial Pyramid Matching encoding\"\n",
    "x_train_ = [spatial_pyramid_matching(x_train[i],\n",
    "                                    x_train_des[i],\n",
    "                                    codebook,\n",
    "                                    level=PYRAMID_LEVEL)\n",
    "                                    for i in range(x_train.shape[0])]\n",
    "\n",
    "x_test_ = [spatial_pyramid_matching(x_test[i],\n",
    "                                   x_test_des[i],\n",
    "                                   codebook,\n",
    "                                   level=PYRAMID_LEVEL) for i in range(x_test.shape[0])]\n",
    "\n",
    "x_train_ = np.asarray(x_train_)\n",
    "x_test_ = np.asarray(x_test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn import svm\n",
    "import numpy as np\n",
    "\n",
    "def svm_classifier(x_train, y_train, x_test=None, y_test=None):\n",
    "#     if x_test == None and y_test == None:\n",
    "#         x_train, x_test, y_train, y_test = train_test_split(\n",
    "#                 x_train, y_train, test_size=0.2, random_state=6)\n",
    "#         print \"Spliting train:{}/test:{} from training data\".format(\n",
    "#                 len(x_train), len(x_test))\n",
    "    C_range = 10.0 ** np.arange(-3, 3)\n",
    "    gamma_range = 10.0 ** np.arange(-3, 3)\n",
    "    param_grid = dict(gamma=gamma_range.tolist(), C=C_range.tolist())\n",
    "\n",
    "    # Grid search for C, gamma, 5-fold CV\n",
    "    print(\"Tuning hyper-parameters\\n\")\n",
    "    clf = GridSearchCV(svm.SVC(), param_grid, cv=5, n_jobs=-2)\n",
    "    clf.fit(x_train, y_train)\n",
    "    print(\"Best parameters set found on development set:\\n\")\n",
    "    print(clf.best_estimator_)\n",
    "    print(\"\\nGrid scores on development set:\\n\")\n",
    "    for params, mean_score, scores in clf.grid_scores_:\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean_score, scores.std() * 2, params))\n",
    "    print(\"\\nDetailed classification report:\\n\")\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\\n\")\n",
    "    y_true, y_pred = y_test, clf.predict(x_test)\n",
    "    #print(classification_report(y_true, y_pred, target_names=get_label()))\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyper-parameters\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape='ovr', degree=3, gamma=0.001, kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 0.001}\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 0.001, 'gamma': 100.0}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 0.001}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 0.01, 'gamma': 100.0}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 0.001}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 0.1, 'gamma': 100.0}\n",
      "0.097 (+/-0.012) for {'C': 1.0, 'gamma': 0.001}\n",
      "0.216 (+/-0.043) for {'C': 1.0, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 1.0, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 1.0, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 1.0, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 1.0, 'gamma': 100.0}\n",
      "0.398 (+/-0.057) for {'C': 10.0, 'gamma': 0.001}\n",
      "0.290 (+/-0.053) for {'C': 10.0, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 10.0, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 10.0, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 10.0, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 10.0, 'gamma': 100.0}\n",
      "0.398 (+/-0.057) for {'C': 100.0, 'gamma': 0.001}\n",
      "0.290 (+/-0.053) for {'C': 100.0, 'gamma': 0.01}\n",
      "0.052 (+/-0.003) for {'C': 100.0, 'gamma': 0.1}\n",
      "0.052 (+/-0.003) for {'C': 100.0, 'gamma': 1.0}\n",
      "0.052 (+/-0.003) for {'C': 100.0, 'gamma': 10.0}\n",
      "0.052 (+/-0.003) for {'C': 100.0, 'gamma': 100.0}\n",
      "\n",
      "Detailed classification report:\n",
      "\n",
      "The model is trained on the full development set.\n",
      "The scores are computed on the full evaluation set.\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          3       0.57      0.67      0.62         6\n",
      "         52       0.20      0.33      0.25         3\n",
      "         62       0.75      0.38      0.50         8\n",
      "         68       0.36      0.67      0.47         6\n",
      "         70       1.00      0.33      0.50         3\n",
      "         78       0.40      0.29      0.33         7\n",
      "         80       0.10      0.20      0.13         5\n",
      "         85       0.09      0.25      0.13         4\n",
      "         95       0.25      0.17      0.20         6\n",
      "        139       0.67      0.33      0.44         6\n",
      "        162       0.00      0.00      0.00         6\n",
      "        165       0.33      0.40      0.36         5\n",
      "        174       0.00      0.00      0.00         1\n",
      "        177       1.00      0.60      0.75         5\n",
      "        184       0.83      0.71      0.77         7\n",
      "        212       1.00      0.40      0.57         5\n",
      "        218       0.50      0.20      0.29         5\n",
      "        235       0.75      0.75      0.75         4\n",
      "        241       0.30      0.43      0.35         7\n",
      "        246       0.33      0.40      0.36         5\n",
      "        248       0.67      0.50      0.57         4\n",
      "\n",
      "avg / total       0.50      0.40      0.42       108\n",
      "\n",
      "0.39814814814814814\n"
     ]
    }
   ],
   "source": [
    "svm_classifier(x_train_, y_train, x_test_, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data multiprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                            img_path label\n",
      "0  ./256_ObjectCategories/139.megaphone/139_0010.jpg   139\n",
      "1  ./256_ObjectCategories/139.megaphone/139_0024.jpg   139\n",
      "2  ./256_ObjectCategories/139.megaphone/139_0075.jpg   139\n",
      "3  ./256_ObjectCategories/139.megaphone/139_0036.jpg   139\n",
      "4  ./256_ObjectCategories/139.megaphone/139_0013.jpg   139\n",
      "(30607, 256, 256, 3)\n",
      "(30607,)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.vq as vq\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "\n",
    "listpath = './img_list.csv'\n",
    "datalist = pd.read_csv(listpath)\n",
    "x, y = [], []\n",
    "print datalist.head()\n",
    "def read_img_and_label(i):\n",
    "    path, label = datalist['img_path'][i], datalist['label'][i]\n",
    "    img = cv2.imread(path)\n",
    "    if img is not None:\n",
    "        if img.shape[:2] != (256,256):\n",
    "            img = cv2.resize(img, (256,256))\n",
    "        return (img, label)\n",
    "#         x.append(img)\n",
    "#         y.append(int(label))\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "pool = multiprocessing.Pool(processes=cores)\n",
    "\n",
    "num = range(len(datalist))\n",
    "for j in pool.imap_unordered(read_img_and_label, num):\n",
    "#     print type(j)\n",
    "#     break\n",
    "    if type(j) is tuple:\n",
    "        (img, label) = j\n",
    "        x.append(img)\n",
    "        y.append(int(label))\n",
    "print np.asarray(x).shape\n",
    "print np.asarray(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
